{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Development\n",
    "## Loan Approval Prediction Using Classical and Modern Machine Learning Techniques\n",
    "\n",
    "**Objective:** Apply classical ML techniques (Logistic Regression, Regularization, PCA, Cross-validation) and modern ML techniques (SVM, Random Forest, XGBoost, Neural Networks) to predict loan approval.\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook Structure\n",
    "1. **Setup and Data Preparation**\n",
    "2. **Logistic Regression (Baseline)**\n",
    "3. **Regularization (L1/L2/ElasticNet)**\n",
    "4. **PCA Analysis**\n",
    "5. **Cross-Validation**\n",
    "6. **Support Vector Machines**\n",
    "7. **Random Forest**\n",
    "8. **XGBoost**\n",
    "9. **Neural Network (MLP)**\n",
    "10. **Model Comparison**\n",
    "11. **Feature Importance Analysis**\n",
    "12. **Conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup and Data Preparation\n",
    "\n",
    "Load the preprocessed dataset and prepare features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1.1 Import Required Libraries\n",
    "# ============================================\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Classical ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Modern ML Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1.2 Load Preprocessed Dataset\n",
    "# ============================================\n",
    "\n",
    "# Load the preprocessed data from Step 2\n",
    "df = pd.read_csv('data/loan_approval_dataset_preprocessed.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1.3 Define Features and Target\n",
    "# ============================================\n",
    "\n",
    "# Features to use for modeling (17 features)\n",
    "feature_columns = [\n",
    "    'no_of_dependents',\n",
    "    'income_annum',\n",
    "    'loan_amount',\n",
    "    'loan_term',\n",
    "    'cibil_score',\n",
    "    'residential_assets_value',\n",
    "    'commercial_assets_value',\n",
    "    'luxury_assets_value',\n",
    "    'bank_asset_value',\n",
    "    'education_encoded',\n",
    "    'self_employed_encoded',\n",
    "    'total_assets_value',\n",
    "    'loan_to_income_ratio',\n",
    "    'assets_to_loan_ratio',\n",
    "    'monthly_income',\n",
    "    'monthly_loan_payment',\n",
    "    'debt_to_income_ratio'\n",
    "]\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df[feature_columns]\n",
    "y = df['loan_status_encoded']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nClass balance: {y.value_counts(normalize=True).round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1.4 Train-Test Split\n",
    "# ============================================\n",
    "\n",
    "# Split data with stratification to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1.5 Feature Scaling\n",
    "# ============================================\n",
    "\n",
    "# Scale features (required for SVM and Neural Networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_columns)\n",
    "\n",
    "print(\"Feature scaling completed!\")\n",
    "print(f\"\\nScaled features mean (should be ~0): {X_train_scaled.mean(axis=0).round(2)[:5]}...\")\n",
    "print(f\"Scaled features std (should be ~1): {X_train_scaled.std(axis=0).round(2)[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1.6 Calculate Class Weights\n",
    "# ============================================\n",
    "\n",
    "# Calculate class weights for handling imbalance\n",
    "n_rejected = (y_train == 1).sum()  # Class 1 is rejected\n",
    "n_approved = (y_train == 0).sum()  # Class 0 is approved\n",
    "\n",
    "# For XGBoost scale_pos_weight\n",
    "scale_pos_weight = n_rejected / n_approved\n",
    "\n",
    "print(f\"Class 0 (Approved): {n_approved} samples\")\n",
    "print(f\"Class 1 (Rejected): {n_rejected} samples\")\n",
    "print(f\"Scale pos weight for XGBoost: {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1.7 Initialize Results Storage\n",
    "# ============================================\n",
    "\n",
    "# Dictionary to store all model results\n",
    "results = {}\n",
    "\n",
    "def evaluate_model(model_name, y_true, y_pred, y_prob=None):\n",
    "    \"\"\"Evaluate model and store results\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    if y_prob is not None:\n",
    "        roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{model_name} Results\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    if roc_auc:\n",
    "        print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    \n",
    "    return results[model_name]\n",
    "\n",
    "print(\"Setup complete! Ready for model training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Logistic Regression (Baseline)\n",
    "\n",
    "**Classical ML Technique #1**\n",
    "\n",
    "Logistic Regression serves as our baseline model. It's interpretable, fast, and provides coefficients that indicate feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2.1 Train Logistic Regression (Baseline)\n",
    "# ============================================\n",
    "\n",
    "# Train logistic regression with balanced class weights\n",
    "lr_baseline = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lr_baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_baseline.predict(X_test_scaled)\n",
    "y_prob_lr = lr_baseline.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('Logistic Regression (Baseline)', y_test, y_pred_lr, y_prob_lr)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Approved', 'Rejected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2.2 Feature Coefficients Analysis\n",
    "# ============================================\n",
    "\n",
    "# Get coefficients and sort by absolute value\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Coefficient': lr_baseline.coef_[0]\n",
    "})\n",
    "coefficients['Abs_Coefficient'] = np.abs(coefficients['Coefficient'])\n",
    "coefficients = coefficients.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Plot coefficients\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['green' if c > 0 else 'red' for c in coefficients['Coefficient']]\n",
    "plt.barh(range(len(coefficients)), coefficients['Coefficient'], color=colors)\n",
    "plt.yticks(range(len(coefficients)), coefficients['Feature'])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Logistic Regression Coefficients\\n(Green = Increases Rejection, Red = Decreases Rejection)')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/lr_coefficients.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features (by coefficient magnitude):\")\n",
    "print(coefficients.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Regularization (L1/L2/ElasticNet)\n",
    "\n",
    "**Classical ML Technique #2**\n",
    "\n",
    "Regularization helps prevent overfitting:\n",
    "- **L1 (Lasso)**: Promotes sparsity, performs feature selection\n",
    "- **L2 (Ridge)**: Handles multicollinearity, shrinks coefficients\n",
    "- **ElasticNet**: Combines L1 and L2 benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3.1 L1 Regularization (Lasso)\n",
    "# ============================================\n",
    "\n",
    "lr_l1 = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    class_weight='balanced',\n",
    "    max_iter=2000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lr_l1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_l1 = lr_l1.predict(X_test_scaled)\n",
    "y_prob_l1 = lr_l1.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('Logistic Regression (L1)', y_test, y_pred_l1, y_prob_l1)\n",
    "\n",
    "# Check which features were zeroed out\n",
    "l1_coef = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'L1_Coefficient': lr_l1.coef_[0]\n",
    "})\n",
    "zeroed_features = l1_coef[l1_coef['L1_Coefficient'] == 0]['Feature'].tolist()\n",
    "print(f\"\\nFeatures zeroed out by L1: {len(zeroed_features)}\")\n",
    "if zeroed_features:\n",
    "    print(f\"Features: {zeroed_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3.2 L2 Regularization (Ridge)\n",
    "# ============================================\n",
    "\n",
    "lr_l2 = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lr_l2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_l2 = lr_l2.predict(X_test_scaled)\n",
    "y_prob_l2 = lr_l2.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('Logistic Regression (L2)', y_test, y_pred_l2, y_prob_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3.3 ElasticNet Regularization\n",
    "# ============================================\n",
    "\n",
    "lr_elasticnet = LogisticRegression(\n",
    "    penalty='elasticnet',\n",
    "    solver='saga',\n",
    "    l1_ratio=0.5,  # 50% L1, 50% L2\n",
    "    class_weight='balanced',\n",
    "    max_iter=2000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lr_elasticnet.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_en = lr_elasticnet.predict(X_test_scaled)\n",
    "y_prob_en = lr_elasticnet.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('Logistic Regression (ElasticNet)', y_test, y_pred_en, y_prob_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3.4 Compare Regularization Methods\n",
    "# ============================================\n",
    "\n",
    "# Compare coefficients across regularization methods\n",
    "reg_comparison = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Baseline': lr_baseline.coef_[0],\n",
    "    'L1 (Lasso)': lr_l1.coef_[0],\n",
    "    'L2 (Ridge)': lr_l2.coef_[0],\n",
    "    'ElasticNet': lr_elasticnet.coef_[0]\n",
    "})\n",
    "\n",
    "print(\"Coefficient Comparison Across Regularization Methods:\")\n",
    "print(reg_comparison.round(4))\n",
    "\n",
    "# Visualize coefficient comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "x = np.arange(len(feature_columns))\n",
    "width = 0.2\n",
    "\n",
    "ax.bar(x - 1.5*width, reg_comparison['Baseline'], width, label='Baseline', alpha=0.8)\n",
    "ax.bar(x - 0.5*width, reg_comparison['L1 (Lasso)'], width, label='L1 (Lasso)', alpha=0.8)\n",
    "ax.bar(x + 0.5*width, reg_comparison['L2 (Ridge)'], width, label='L2 (Ridge)', alpha=0.8)\n",
    "ax.bar(x + 1.5*width, reg_comparison['ElasticNet'], width, label='ElasticNet', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Coefficient Value')\n",
    "ax.set_title('Coefficient Comparison Across Regularization Methods')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(feature_columns, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/regularization_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: PCA Analysis\n",
    "\n",
    "**Classical ML Technique #3**\n",
    "\n",
    "Principal Component Analysis (PCA) reduces dimensionality while preserving variance. We'll analyze how many components are needed and compare model performance with/without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4.1 Fit PCA and Analyze Variance\n",
    "# ============================================\n",
    "\n",
    "# Fit PCA on all components\n",
    "pca_full = PCA(random_state=RANDOM_STATE)\n",
    "pca_full.fit(X_train_scaled)\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance = pca_full.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Find number of components for 95% variance\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "\n",
    "print(f\"Number of components for 95% variance: {n_components_95}\")\n",
    "print(f\"\\nExplained Variance Ratio (first 10 components):\")\n",
    "for i, (var, cum) in enumerate(zip(explained_variance[:10], cumulative_variance[:10])):\n",
    "    print(f\"  PC{i+1}: {var:.4f} (Cumulative: {cum:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4.2 Visualize Explained Variance\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Individual explained variance\n",
    "axes[0].bar(range(1, len(explained_variance)+1), explained_variance, alpha=0.7, color='steelblue')\n",
    "axes[0].set_xlabel('Principal Component')\n",
    "axes[0].set_ylabel('Explained Variance Ratio')\n",
    "axes[0].set_title('Individual Explained Variance by Component')\n",
    "\n",
    "# Cumulative explained variance\n",
    "axes[1].plot(range(1, len(cumulative_variance)+1), cumulative_variance, 'bo-', linewidth=2)\n",
    "axes[1].axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "axes[1].axvline(x=n_components_95, color='g', linestyle='--', label=f'{n_components_95} Components')\n",
    "axes[1].set_xlabel('Number of Components')\n",
    "axes[1].set_ylabel('Cumulative Explained Variance')\n",
    "axes[1].set_title('Cumulative Explained Variance')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/pca_variance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4.3 Train Logistic Regression with PCA\n",
    "# ============================================\n",
    "\n",
    "# Apply PCA with n_components for 95% variance\n",
    "pca = PCA(n_components=n_components_95, random_state=RANDOM_STATE)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Original features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"PCA features: {X_train_pca.shape[1]}\")\n",
    "print(f\"Dimensionality reduction: {(1 - X_train_pca.shape[1]/X_train_scaled.shape[1])*100:.1f}%\")\n",
    "\n",
    "# Train Logistic Regression on PCA features\n",
    "lr_pca = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_pca = lr_pca.predict(X_test_pca)\n",
    "y_prob_pca = lr_pca.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('Logistic Regression (PCA)', y_test, y_pred_pca, y_prob_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4.4 Compare With/Without PCA\n",
    "# ============================================\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['Without PCA', 'With PCA'],\n",
    "    'Features': [17, n_components_95],\n",
    "    'Accuracy': [results['Logistic Regression (Baseline)']['Accuracy'], \n",
    "                 results['Logistic Regression (PCA)']['Accuracy']],\n",
    "    'F1-Score': [results['Logistic Regression (Baseline)']['F1-Score'], \n",
    "                 results['Logistic Regression (PCA)']['F1-Score']],\n",
    "    'ROC-AUC': [results['Logistic Regression (Baseline)']['ROC-AUC'], \n",
    "               results['Logistic Regression (PCA)']['ROC-AUC']]\n",
    "}\n",
    "\n",
    "pca_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\nPCA Comparison:\")\n",
    "print(pca_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Cross-Validation\n",
    "\n",
    "**Classical ML Technique #4**\n",
    "\n",
    "K-Fold Cross-Validation provides more reliable performance estimates. We use Stratified K-Fold to maintain class distribution in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5.1 Setup Cross-Validation\n",
    "# ============================================\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Models to cross-validate\n",
    "cv_models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE),\n",
    "    'LR with L1': LogisticRegression(penalty='l1', solver='saga', class_weight='balanced', max_iter=2000, random_state=RANDOM_STATE),\n",
    "    'LR with L2': LogisticRegression(penalty='l2', class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE),\n",
    "    'LR with ElasticNet': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, class_weight='balanced', max_iter=2000, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "print(f\"Cross-Validation Setup:\")\n",
    "print(f\"  - K-Folds: 5\")\n",
    "print(f\"  - Stratified: Yes\")\n",
    "print(f\"  - Models: {list(cv_models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5.2 Perform Cross-Validation\n",
    "# ============================================\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for model_name, model in cv_models.items():\n",
    "    # Cross-validate for accuracy\n",
    "    accuracy_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "    # Cross-validate for F1\n",
    "    f1_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='f1')\n",
    "    # Cross-validate for ROC-AUC\n",
    "    roc_auc_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    cv_results[model_name] = {\n",
    "        'Accuracy': f\"{accuracy_scores.mean():.4f} ± {accuracy_scores.std():.4f}\",\n",
    "        'F1-Score': f\"{f1_scores.mean():.4f} ± {f1_scores.std():.4f}\",\n",
    "        'ROC-AUC': f\"{roc_auc_scores.mean():.4f} ± {roc_auc_scores.std():.4f}\",\n",
    "        'Accuracy_mean': accuracy_scores.mean(),\n",
    "        'F1_mean': f1_scores.mean(),\n",
    "        'ROC_AUC_mean': roc_auc_scores.mean()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Accuracy: {cv_results[model_name]['Accuracy']}\")\n",
    "    print(f\"  F1-Score: {cv_results[model_name]['F1-Score']}\")\n",
    "    print(f\"  ROC-AUC:  {cv_results[model_name]['ROC-AUC']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5.3 Visualize Cross-Validation Results\n",
    "# ============================================\n",
    "\n",
    "# Prepare data for plotting\n",
    "model_names = list(cv_results.keys())\n",
    "accuracy_means = [cv_results[m]['Accuracy_mean'] for m in model_names]\n",
    "f1_means = [cv_results[m]['F1_mean'] for m in model_names]\n",
    "roc_auc_means = [cv_results[m]['ROC_AUC_mean'] for m in model_names]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width, accuracy_means, width, label='Accuracy', color='steelblue')\n",
    "bars2 = ax.bar(x, f1_means, width, label='F1-Score', color='darkorange')\n",
    "bars3 = ax.bar(x + width, roc_auc_means, width, label='ROC-AUC', color='green')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('5-Fold Cross-Validation Results - Classical ML Models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/cv_results_classical.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Support Vector Machines\n",
    "\n",
    "**Modern ML Technique #1**\n",
    "\n",
    "SVM finds the optimal hyperplane to separate classes. We'll compare different kernels:\n",
    "- **Linear**: Linear decision boundary\n",
    "- **RBF**: Non-linear, handles complex patterns\n",
    "- **Polynomial**: Non-linear with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6.1 SVM with Linear Kernel\n",
    "# ============================================\n",
    "\n",
    "svm_linear = SVC(\n",
    "    kernel='linear',\n",
    "    class_weight='balanced',\n",
    "    probability=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "svm_linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm_linear = svm_linear.predict(X_test_scaled)\n",
    "y_prob_svm_linear = svm_linear.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('SVM (Linear)', y_test, y_pred_svm_linear, y_prob_svm_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6.2 SVM with RBF Kernel\n",
    "# ============================================\n",
    "\n",
    "svm_rbf = SVC(\n",
    "    kernel='rbf',\n",
    "    class_weight='balanced',\n",
    "    probability=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm_rbf = svm_rbf.predict(X_test_scaled)\n",
    "y_prob_svm_rbf = svm_rbf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('SVM (RBF)', y_test, y_pred_svm_rbf, y_prob_svm_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6.3 SVM with Polynomial Kernel\n",
    "# ============================================\n",
    "\n",
    "svm_poly = SVC(\n",
    "    kernel='poly',\n",
    "    degree=3,\n",
    "    class_weight='balanced',\n",
    "    probability=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "svm_poly.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm_poly = svm_poly.predict(X_test_scaled)\n",
    "y_prob_svm_poly = svm_poly.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('SVM (Polynomial)', y_test, y_pred_svm_poly, y_prob_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6.4 SVM Hyperparameter Tuning (RBF)\n",
    "# ============================================\n",
    "\n",
    "# GridSearchCV for RBF kernel\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=RANDOM_STATE),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {svm_grid.best_params_}\")\n",
    "print(f\"Best CV F1-Score: {svm_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_svm_best = svm_grid.predict(X_test_scaled)\n",
    "y_prob_svm_best = svm_grid.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "evaluate_model('SVM (Tuned RBF)', y_test, y_pred_svm_best, y_prob_svm_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Random Forest\n",
    "\n",
    "**Modern ML Technique #2**\n",
    "\n",
    "Random Forest is an ensemble method that builds multiple decision trees and combines their predictions. It provides:\n",
    "- Robust predictions through averaging\n",
    "- Built-in feature importance\n",
    "- Resistance to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7.1 Train Random Forest\n",
    "# ============================================\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "y_prob_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('Random Forest', y_test, y_pred_rf, y_prob_rf)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7.2 Random Forest Feature Importance\n",
    "# ============================================\n",
    "\n",
    "# Get feature importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(rf_importance)), rf_importance['Importance'], color='forestgreen')\n",
    "plt.yticks(range(len(rf_importance)), rf_importance['Feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/rf_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features (Random Forest):\")\n",
    "print(rf_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7.3 Random Forest Hyperparameter Tuning\n",
    "# ============================================\n",
    "\n",
    "# GridSearchCV for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best CV F1-Score: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_rf_best = rf_grid.predict(X_test_scaled)\n",
    "y_prob_rf_best = rf_grid.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "evaluate_model('Random Forest (Tuned)', y_test, y_pred_rf_best, y_prob_rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: XGBoost\n",
    "\n",
    "**Modern ML Technique #3**\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is a powerful ensemble method that builds trees sequentially, with each tree correcting errors from previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8.1 Train XGBoost\n",
    "# ============================================\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    scale_pos_weight=scale_pos_weight,  # Handle class imbalance\n",
    "    random_state=RANDOM_STATE,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb.predict(X_test_scaled)\n",
    "y_prob_xgb = xgb.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('XGBoost', y_test, y_pred_xgb, y_prob_xgb)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8.2 XGBoost Feature Importance\n",
    "# ============================================\n",
    "\n",
    "# Get feature importance (by gain)\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': xgb.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(xgb_importance)), xgb_importance['Importance'], color='darkorange')\n",
    "plt.yticks(range(len(xgb_importance)), xgb_importance['Feature'])\n",
    "plt.xlabel('Feature Importance (Gain)')\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/xgb_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features (XGBoost):\")\n",
    "print(xgb_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8.3 Compare RF and XGBoost Feature Importance\n",
    "# ============================================\n",
    "\n",
    "# Merge feature importance from both models\n",
    "importance_comparison = rf_importance.merge(\n",
    "    xgb_importance, on='Feature', suffixes=('_RF', '_XGB')\n",
    ")\n",
    "\n",
    "# Plot side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Random Forest\n",
    "rf_sorted = importance_comparison.sort_values('Importance_RF', ascending=True)\n",
    "axes[0].barh(rf_sorted['Feature'], rf_sorted['Importance_RF'], color='forestgreen')\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Random Forest Feature Importance')\n",
    "\n",
    "# XGBoost\n",
    "xgb_sorted = importance_comparison.sort_values('Importance_XGB', ascending=True)\n",
    "axes[1].barh(xgb_sorted['Feature'], xgb_sorted['Importance_XGB'], color='darkorange')\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('XGBoost Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/feature_importance_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Neural Network (MLP)\n",
    "\n",
    "**Modern ML Technique #4**\n",
    "\n",
    "Multi-Layer Perceptron (MLP) is a feedforward neural network that can learn complex non-linear patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9.1 Build Neural Network Architecture\n",
    "# ============================================\n",
    "\n",
    "def build_nn_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "nn_model = build_nn_model(X_train_scaled.shape[1])\n",
    "\n",
    "# Display model summary\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9.2 Train Neural Network\n",
    "# ============================================\n",
    "\n",
    "# Calculate class weights for imbalanced data\n",
    "class_weights = {\n",
    "    0: 1.0,  # Approved\n",
    "    1: scale_pos_weight  # Rejected\n",
    "}\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9.3 Visualize Training History\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/nn_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9.4 Evaluate Neural Network\n",
    "# ============================================\n",
    "\n",
    "# Predictions\n",
    "y_prob_nn = nn_model.predict(X_test_scaled).flatten()\n",
    "y_pred_nn = (y_prob_nn > 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model('Neural Network', y_test, y_pred_nn, y_prob_nn)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Model Comparison\n",
    "\n",
    "Compare all models across multiple metrics to identify the best performer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10.1 Create Comparison Table\n",
    "# ============================================\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "# Sort by F1-Score (our primary metric for imbalanced data)\n",
    "results_df = results_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string())\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10.2 Visualize Model Comparison\n",
    "# ============================================\n",
    "\n",
    "# Prepare data for visualization\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "models = results_df.index.tolist()\n",
    "\n",
    "# Create grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.15\n",
    "\n",
    "colors = ['steelblue', 'darkorange', 'green', 'red', 'purple']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = results_df[metric].values\n",
    "    ax.bar(x + i*width, values, width, label=metric, color=colors[i])\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Comparison Across All Metrics')\n",
    "ax.set_xticks(x + width * 2)\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10.3 ROC Curves Comparison\n",
    "# ============================================\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Store predictions for ROC curves\n",
    "roc_data = {\n",
    "    'Logistic Regression': y_prob_lr,\n",
    "    'LR (L1)': y_prob_l1,\n",
    "    'SVM (RBF)': y_prob_svm_rbf,\n",
    "    'Random Forest': y_prob_rf,\n",
    "    'XGBoost': y_prob_xgb,\n",
    "    'Neural Network': y_prob_nn\n",
    "}\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(roc_data)))\n",
    "\n",
    "for (name, y_prob), color in zip(roc_data.items(), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{name} (AUC = {auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/roc_curves_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10.4 Best Model Identification\n",
    "# ============================================\n",
    "\n",
    "# Find best model by F1-Score\n",
    "best_model = results_df['F1-Score'].idxmax()\n",
    "best_f1 = results_df.loc[best_model, 'F1-Score']\n",
    "\n",
    "# Find best model by ROC-AUC\n",
    "best_model_auc = results_df['ROC-AUC'].idxmax()\n",
    "best_auc = results_df.loc[best_model_auc, 'ROC-AUC']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BEST MODEL IDENTIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest Model by F1-Score: {best_model}\")\n",
    "print(f\"  F1-Score: {best_f1:.4f}\")\n",
    "print(f\"\\nBest Model by ROC-AUC: {best_model_auc}\")\n",
    "print(f\"  ROC-AUC: {best_auc:.4f}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11: Feature Importance Analysis\n",
    "\n",
    "Aggregate feature importance from multiple models to identify the most influential predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 11.1 Aggregate Feature Importance\n",
    "# ============================================\n",
    "\n",
    "# Normalize coefficients from Logistic Regression\n",
    "lr_coef_normalized = np.abs(lr_baseline.coef_[0]) / np.abs(lr_baseline.coef_[0]).sum()\n",
    "\n",
    "# Create aggregate importance DataFrame\n",
    "aggregate_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Logistic_Regression': lr_coef_normalized,\n",
    "    'Random_Forest': rf.feature_importances_,\n",
    "    'XGBoost': xgb.feature_importances_\n",
    "})\n",
    "\n",
    "# Calculate average importance\n",
    "aggregate_importance['Average'] = aggregate_importance[['Logistic_Regression', 'Random_Forest', 'XGBoost']].mean(axis=1)\n",
    "aggregate_importance = aggregate_importance.sort_values('Average', ascending=False)\n",
    "\n",
    "print(\"Aggregate Feature Importance (Top 10):\")\n",
    "print(aggregate_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 11.2 Visualize Aggregate Feature Importance\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Top 10 features by average importance\n",
    "top_features = aggregate_importance.head(10)\n",
    "\n",
    "# Bar chart of average importance\n",
    "axes[0].barh(range(len(top_features)), top_features['Average'], color='steelblue')\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['Feature'])\n",
    "axes[0].set_xlabel('Average Importance')\n",
    "axes[0].set_title('Top 10 Features by Average Importance')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Heatmap of importance across models\n",
    "heatmap_data = aggregate_importance.set_index('Feature')[['Logistic_Regression', 'Random_Forest', 'XGBoost']]\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[1])\n",
    "axes[1].set_title('Feature Importance Heatmap Across Models')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('presentation_images/aggregate_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 11.3 Top 5 Predictors with Business Interpretation\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TOP 5 PREDICTORS OF LOAN APPROVAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "top_5 = aggregate_importance.head(5)\n",
    "\n",
    "interpretations = {\n",
    "    'cibil_score': 'Credit score is the strongest indicator of creditworthiness',\n",
    "    'loan_to_income_ratio': 'Higher ratio indicates higher loan burden relative to income',\n",
    "    'debt_to_income_ratio': 'Critical financial health indicator',\n",
    "    'assets_to_loan_ratio': 'Measures collateral coverage for the loan',\n",
    "    'income_annum': 'Higher income increases ability to repay',\n",
    "    'total_assets_value': 'Total assets provide financial security',\n",
    "    'loan_amount': 'Larger loans carry higher risk',\n",
    "    'monthly_loan_payment': 'Higher payments strain monthly budget',\n",
    "    'monthly_income': 'Regular income ensures repayment capacity',\n",
    "    'loan_term': 'Longer terms affect total interest paid'\n",
    "}\n",
    "\n",
    "for i, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "    feature = row['Feature']\n",
    "    avg_importance = row['Average']\n",
    "    interpretation = interpretations.get(feature, 'Important predictor of loan approval')\n",
    "    \n",
    "    print(f\"\\n{i}. {feature}\")\n",
    "    print(f\"   Average Importance: {avg_importance:.4f}\")\n",
    "    print(f\"   Interpretation: {interpretation}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12: Conclusions\n",
    "\n",
    "Summary of findings and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 12.1 Final Summary\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 3: MODEL DEVELOPMENT - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n📊 DATASET OVERVIEW\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Total Samples: 4,269\")\n",
    "print(f\"Features Used: 17\")\n",
    "print(f\"Class Distribution: 62% Rejected, 38% Approved\")\n",
    "print(f\"Train/Test Split: 80/20 (Stratified)\")\n",
    "\n",
    "print(\"\\n🔧 CLASSICAL ML TECHNIQUES\")\n",
    "print(\"-\"*40)\n",
    "print(\"✓ Logistic Regression (Baseline)\")\n",
    "print(\"✓ Regularization (L1/L2/ElasticNet)\")\n",
    "print(\"✓ Principal Component Analysis (PCA)\")\n",
    "print(\"✓ Cross-Validation (5-Fold Stratified)\")\n",
    "\n",
    "print(\"\\n🚀 MODERN ML TECHNIQUES\")\n",
    "print(\"-\"*40)\n",
    "print(\"✓ Support Vector Machines (Linear, RBF, Polynomial)\")\n",
    "print(\"✓ Random Forest Classifier\")\n",
    "print(\"✓ XGBoost (Gradient Boosting)\")\n",
    "print(\"✓ Neural Network (MLP)\")\n",
    "\n",
    "print(\"\\n🏆 BEST MODEL\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Model: {best_model}\")\n",
    "print(f\"F1-Score: {best_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {results_df.loc[best_model, 'ROC-AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n📈 TOP 5 PREDICTORS\")\n",
    "print(\"-\"*40)\n",
    "for i, (_, row) in enumerate(aggregate_importance.head(5).iterrows(), 1):\n",
    "    print(f\"{i}. {row['Feature']} (Importance: {row['Average']:.4f})\")\n",
    "\n",
    "print(\"\\n💡 KEY FINDINGS\")\n",
    "print(\"-\"*40)\n",
    "print(\"1. CIBIL score is the most important predictor of loan approval\")\n",
    "print(\"2. Financial ratios (debt-to-income, loan-to-income) are critical\")\n",
    "print(\"3. Modern ML techniques (RF, XGBoost) outperform classical methods\")\n",
    "print(\"4. Class imbalance was effectively handled with balanced weights\")\n",
    "print(\"5. Feature engineering improved model interpretability\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 12.2 Save Final Results\n",
    "# ============================================\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('data/model_results.csv')\n",
    "aggregate_importance.to_csv('data/feature_importance.csv', index=False)\n",
    "\n",
    "print(\"Results saved to:\")\n",
    "print(\"  - data/model_results.csv\")\n",
    "print(\"  - data/feature_importance.csv\")\n",
    "print(\"\\nVisualization images saved to presentation_images/ folder:\")\n",
    "print(\"  - lr_coefficients.png\")\n",
    "print(\"  - regularization_comparison.png\")\n",
    "print(\"  - pca_variance.png\")\n",
    "print(\"  - cv_results_classical.png\")\n",
    "print(\"  - rf_feature_importance.png\")\n",
    "print(\"  - xgb_feature_importance.png\")\n",
    "print(\"  - feature_importance_comparison.png\")\n",
    "print(\"  - nn_training_curves.png\")\n",
    "print(\"  - model_comparison.png\")\n",
    "print(\"  - roc_curves_comparison.png\")\n",
    "print(\"  - aggregate_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 12.3 Classical vs Modern ML Comparison\n",
    "# ============================================\n",
    "\n",
    "# Categorize models\n",
    "classical_models = ['Logistic Regression (Baseline)', 'Logistic Regression (L1)', \n",
    "                    'Logistic Regression (L2)', 'Logistic Regression (ElasticNet)', \n",
    "                    'Logistic Regression (PCA)']\n",
    "modern_models = ['SVM (Linear)', 'SVM (RBF)', 'SVM (Polynomial)', 'SVM (Tuned RBF)',\n",
    "                 'Random Forest', 'Random Forest (Tuned)', 'XGBoost', 'Neural Network']\n",
    "\n",
    "# Calculate average metrics for each category\n",
    "classical_results = results_df[results_df.index.isin(classical_models)]\n",
    "modern_results = results_df[results_df.index.isin(modern_models)]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLASSICAL vs MODERN ML COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(classical_results) > 0:\n",
    "    print(f\"\\nClassical ML (avg of {len(classical_results)} models):\")\n",
    "    print(f\"  Accuracy:  {classical_results['Accuracy'].mean():.4f}\")\n",
    "    print(f\"  F1-Score:  {classical_results['F1-Score'].mean():.4f}\")\n",
    "    print(f\"  ROC-AUC:   {classical_results['ROC-AUC'].mean():.4f}\")\n",
    "\n",
    "if len(modern_results) > 0:\n",
    "    print(f\"\\nModern ML (avg of {len(modern_results)} models):\")\n",
    "    print(f\"  Accuracy:  {modern_results['Accuracy'].mean():.4f}\")\n",
    "    print(f\"  F1-Score:  {modern_results['F1-Score'].mean():.4f}\")\n",
    "    print(f\"  ROC-AUC:   {modern_results['ROC-AUC'].mean():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nREADY FOR STEP 4: EVALUATION & ANALYSIS\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary for Presentation\n",
    "\n",
    "### Key Slides to Create:\n",
    "\n",
    "1. **Model Development Overview** - Techniques applied\n",
    "2. **Data Preparation** - 17 features, 80/20 split, scaling\n",
    "3. **Logistic Regression** - Baseline results + coefficients\n",
    "4. **Regularization** - L1/L2/ElasticNet comparison\n",
    "5. **PCA Analysis** - Variance explained + performance\n",
    "6. **Cross-Validation** - 5-Fold results chart\n",
    "7. **SVM Results** - Kernel comparison\n",
    "8. **Random Forest** - Results + feature importance\n",
    "9. **XGBoost** - Results + feature importance\n",
    "10. **Neural Network** - Architecture + training curves\n",
    "11. **Model Comparison** - Summary table + ROC curves\n",
    "12. **Feature Importance** - Top predictors\n",
    "13. **Conclusions** - Best model + key findings\n",
    "\n",
    "### Images Generated:\n",
    "All visualization images are saved in `presentation_images/` folder and ready for use in your presentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
